{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtmeM4RI5qYe"
      },
      "source": [
        "# Welcome to ECE 5460 Pytorch Tutorial!\n",
        "\n",
        "OSU ECE 5460\n",
        "\n",
        "In this tutorial, we will get familar with...\n",
        "\n",
        "- basic usage of pytorch\n",
        "- structure of training, validation, and testing\n",
        "- checkpointing and telemetries\n",
        "\n",
        "Written by Yuyi Chang (chang.1560@osu.edu) with inspirations and materials taken from [MIT 6.8300/6.8301](http://6.8300.csail.mit.edu/sp23/schedule.html), and official documentations.\n",
        "\n",
        "\n",
        "> Before you start: make a copy of this file and saved to your account by `File - Save a copy in Drive`\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QipPcI_E9RyO"
      },
      "source": [
        "## 1.1 Getting started with pytorch\n",
        "\n",
        "1. A Python GPU-accelerated tensor library (NumPy, but faster)\n",
        "2. Differentiable Programming with dynamic computation graphs\n",
        "3. Flexible and efficient **neural network** library\n",
        "4. Python-first framework (easy to integrate with other Python libraries, debug, and extend)\n",
        "  + Quick conversion from & to NumPy array, integration with other Python libs.\n",
        "  + Your favorite Python debugger.\n",
        "  + Adding custom ops with Python/c++ extension.\n",
        "  + Running in purely c++ environment with the c++ API.\n",
        "\n",
        "Colab has pytorch preinstalled. You can load the torch package by `import torch`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VYEzrOHr6KMH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.9.1\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Av6XkS_u9cMq"
      },
      "source": [
        "Literally any operation in `numpy` has its counterpart in `torch` - with a slight difference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "mzRG9NkD6niL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== numpy ===\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "=== torch ===\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "\n",
            "=== getting shapes ===\n",
            "numpy (2, 3)\n",
            "torch torch.Size([2, 3])\n",
            "\n",
            " === numpy to torch === \n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]], dtype=torch.float64)\n",
            "\n",
            " === torch to numpy === \n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "=== casting types === \n",
            "torch.float32\n",
            "torch.float16\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# zero array, same thing for ones, rand, and more!\n",
        "a = np.zeros((2, 3))\n",
        "print(\"=== numpy ===\")\n",
        "print(a)\n",
        "\n",
        "b = torch.zeros(2, 3)\n",
        "print(\"=== torch ===\")\n",
        "print(b)\n",
        "\n",
        "# getting shape\n",
        "print(\"\\n=== getting shapes ===\")\n",
        "print(\"numpy\", a.shape)\n",
        "print(\"torch\", b.size())\n",
        "\n",
        "# you can convert numpy to tensor\n",
        "c = torch.as_tensor(a) # or torch.Tensor(a)\n",
        "print(\"\\n === numpy to torch === \")\n",
        "print(c)\n",
        "\n",
        "# or tensor to numpy\n",
        "print(\"\\n === torch to numpy === \")\n",
        "d = b.numpy()   # or np.array(b) or np.asarray(b)\n",
        "print(d)\n",
        "\n",
        "# casting types\n",
        "aa = torch.zeros(2, 3)\n",
        "print('=== casting types === ')\n",
        "print(aa.dtype)\n",
        "bb = aa.half()\n",
        "print(bb.dtype)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQZeA31SAXDN"
      },
      "source": [
        "## 1.2 Using GPU\n",
        "\n",
        "Important on colab, check if you are using GPU runtime for running any model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "m5-crBNX6sap"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "using device: cpu\n"
          ]
        }
      ],
      "source": [
        "# check if there is CUDA device available\n",
        "torch.cuda.is_available()\n",
        "\n",
        "device = torch.device('cuda:0') if torch.cuda.is_available() else 'cpu'\n",
        "print(\"using device: {}\".format(device))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0pLTYJAA8dC"
      },
      "source": [
        "An array can be moved between devices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KDLskyZgAp-y"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1, 0, 8],\n",
            "        [6, 4, 0]])\n",
            "tensor([[1, 0, 8],\n",
            "        [6, 4, 0]])\n",
            "tensor([[1, 0, 8],\n",
            "        [6, 4, 0]])\n"
          ]
        }
      ],
      "source": [
        "# define a new tensor\n",
        "a = torch.randint(0, 10, (2, 3))\n",
        "print(a)\n",
        "\n",
        "b = a.to(device)\n",
        "print(b)\n",
        "\n",
        "c = b.cpu()\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWPLwFeJCNRn"
      },
      "source": [
        "Performing operations between two tensors not on the same device will result an error (very common when writing training code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4ad80IgfCSf0"
      },
      "outputs": [],
      "source": [
        "# this will result runtime error\n",
        "aa = b + c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgMAwejTDBvI"
      },
      "source": [
        "## 1.3 Gradient in PyTorch\n",
        "\n",
        "What makes Pytorch to be very unique is the ability to calculate gradient, which is essential for any gradient-based optimization problems.\n",
        "Pytorch uses [reverse-mode automatic differentiation](https://en.wikipedia.org/wiki/Automatic_differentiation) to compute gradients through any tensor operations.\n",
        "\n",
        "More details at https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "9sBtuSc3CVUi"
      },
      "outputs": [],
      "source": [
        "# start with an array full of ones\n",
        "a = torch.ones(2, 3, requires_grad=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "3vlThAEXEd7h"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "# initially a has no gradient\n",
        "print(a.grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "wMmXbm7_EnDn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(6., grad_fn=<SumBackward0>)\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n"
          ]
        }
      ],
      "source": [
        "# gradient will automatically flow during calculations\n",
        "b = a.sum()\n",
        "print(b)\n",
        "\n",
        "# calculate gradient\n",
        "b.backward()\n",
        "print(a.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXNcfntZE707"
      },
      "source": [
        "What happens if you run `b = a.sum()` multiple times?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "kSDRn2sFFBN7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(6., grad_fn=<SumBackward0>)\n",
            "tensor([[2., 2., 2.],\n",
            "        [2., 2., 2.]])\n"
          ]
        }
      ],
      "source": [
        "# just repeating...\n",
        "# gradient will automatically flow during calculations\n",
        "b = a.sum()\n",
        "print(b)\n",
        "\n",
        "# calculate gradient\n",
        "b.backward()\n",
        "print(a.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryzTR0JlFEgX"
      },
      "source": [
        "What you observed is the gradient is being accumulated.\n",
        "It can be cleared by running"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "dGVGOGP1FTDB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ]
        }
      ],
      "source": [
        "a.grad.zero_()\n",
        "print(a.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Why is the gradient all 1s?\n",
        "\n",
        "When you compute `b = a.sum()` and then call `b.backward()`, the gradient stored in `a.grad` is all 1s. Here's why:\n",
        "\n",
        "**Mathematical explanation:**\n",
        "- If `a` is a tensor with elements `a[i,j]`, and `b = a.sum()` = `a[0,0] + a[0,1] + a[0,2] + a[1,0] + a[1,1] + a[1,2]`\n",
        "- The gradient `∂b/∂a[i,j]` tells us: \"How much does `b` change when `a[i,j]` changes by 1?\"\n",
        "- Since `b` is the sum of all elements, each element contributes equally: **∂b/∂a[i,j] = 1** for all `i,j`\n",
        "- This means: increasing any element of `a` by 1 increases `b` by exactly 1\n",
        "\n",
        "**Intuitive explanation:**\n",
        "- Each element in `a` contributes equally to the sum\n",
        "- There's no weighting or multiplication - it's just addition\n",
        "- So the \"sensitivity\" of the sum to each element is the same: 1\n",
        "\n",
        "This is different from other operations. For example, if we had `b = a.mean()`, the gradient would be `1/n` (where n is the number of elements), because each element contributes `1/n` to the mean.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gradient after sum():\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "Explanation: Each element contributes equally (1) to the sum\n",
            "\n",
            "Gradient after mean():\n",
            "tensor([[0.1667, 0.1667, 0.1667],\n",
            "        [0.1667, 0.1667, 0.1667]])\n",
            "Explanation: Each element contributes 1/6 = 0.1667 to the mean\n",
            "\n",
            "Gradient after weighted sum (a * weights).sum():\n",
            "tensor([[2., 3., 4.],\n",
            "        [5., 6., 7.]])\n",
            "Explanation: Each element's gradient equals its weight\n"
          ]
        }
      ],
      "source": [
        "# Demonstration: Compare gradients for different operations\n",
        "a = torch.ones(2, 3, requires_grad=True)\n",
        "\n",
        "# Operation 1: Sum (gradient = 1 for each element)\n",
        "a.grad = None  # Clear previous gradients\n",
        "b_sum = a.sum()\n",
        "b_sum.backward()\n",
        "print(\"Gradient after sum():\")\n",
        "print(a.grad)\n",
        "print(\"Explanation: Each element contributes equally (1) to the sum\\n\")\n",
        "\n",
        "# Operation 2: Mean (gradient = 1/n for each element)\n",
        "a.grad = None\n",
        "b_mean = a.mean()\n",
        "b_mean.backward()\n",
        "print(\"Gradient after mean():\")\n",
        "print(a.grad)\n",
        "print(f\"Explanation: Each element contributes 1/{a.numel()} = {1/a.numel():.4f} to the mean\\n\")\n",
        "\n",
        "# Operation 3: Weighted sum (gradient = weight for each element)\n",
        "a.grad = None\n",
        "weights = torch.tensor([[2.0, 3.0, 4.0], [5.0, 6.0, 7.0]])\n",
        "b_weighted = (a * weights).sum()\n",
        "b_weighted.backward()\n",
        "print(\"Gradient after weighted sum (a * weights).sum():\")\n",
        "print(a.grad)\n",
        "print(\"Explanation: Each element's gradient equals its weight\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBbJ7439FX0h"
      },
      "source": [
        "## 2. Building a model in PyTorch\n",
        "\n",
        "Pytorch provides a large collection of building blocks to build a model in any sizes.\n",
        "\n",
        "- affine layers\n",
        "- activation functions\n",
        "- normalization layers\n",
        "- [Initialization schemes](https://pytorch.org/docs/stable/nn.html#torch-nn-init)\n",
        "- [Loss functions](https://pytorch.org/docs/stable/nn.html#loss-functions)\n",
        "- [Embeddings](https://pytorch.org/docs/stable/nn.html#sparse-layers)\n",
        "- [Distributed and Multi-GPU training](https://pytorch.org/docs/stable/nn.html#dataparallel-layers-multi-gpu-distributed)\n",
        "- [Gradient-based optimizers](https://pytorch.org/docs/stable/optim.html)\n",
        "- [Learning rate schedulers](https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate)\n",
        "- etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TB8WjaQsGjVF"
      },
      "source": [
        "## 2.1 Linear regression with `nn.Linear()`\n",
        "\n",
        "Suppose we want to solve a linear regression problem\n",
        "\n",
        "$$y = \\beta_0 + \\beta_1 * x$$\n",
        "\n",
        "Let's start by generating some data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "kwi-zsC1GGbr"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "num_sample = 100\n",
        "num_feature = 1\n",
        "\n",
        "secret_pin = 0 # the actual pin will be given in the lecture\n",
        "\n",
        "np.random.seed(secret_pin)\n",
        "X = 5 * np.random.rand(num_sample, num_feature)\n",
        "beta = np.array([5])\n",
        "y = np.dot(X, beta) + np.random.randn(100) * 0.5\n",
        "\n",
        "plt.plot(X[:,0], y, '.')\n",
        "plt.xlabel('x_0')\n",
        "plt.ylabel('y')\n",
        "\n",
        "# Convert NumPy arrays to PyTorch tensors\n",
        "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(y, dtype=torch.float32).unsqueeze(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "BUZjQOm6JUon"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# Define a linear regression model\n",
        "class LinearRegressionModel(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(input_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "# Create the model\n",
        "input_size = 1  # 10 input features\n",
        "output_size = 1  # 1 output (predicted value)\n",
        "model = LinearRegressionModel(input_size, output_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "DavfytFZJMHk"
      },
      "outputs": [],
      "source": [
        "# Define the loss function and optimizer\n",
        "import torch.optim as optim\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.02)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJuwLn6oJEWa"
      },
      "source": [
        "Putting everything together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Vm_DUkCUIxhh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [500/5000], Loss: 3.7694\n",
            "Epoch [1000/5000], Loss: 1.2699\n",
            "Epoch [1500/5000], Loss: 0.4090\n",
            "Epoch [2000/5000], Loss: 0.2604\n",
            "Epoch [2500/5000], Loss: 0.2485\n",
            "Epoch [3000/5000], Loss: 0.2481\n",
            "Epoch [3500/5000], Loss: 0.2481\n",
            "Epoch [4000/5000], Loss: 0.2481\n",
            "Epoch [4500/5000], Loss: 0.2481\n",
            "Epoch [5000/5000], Loss: 0.2481\n",
            "Final model parameters:\n",
            "linear.weight tensor([[4.9937]])\n",
            "linear.bias tensor([0.1111])\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "# Convert NumPy arrays to PyTorch tensors\n",
        "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(y, dtype=torch.float32).unsqueeze(-1)\n",
        "\n",
        "X_tensor = X_tensor.to(device)\n",
        "y_tensor = y_tensor.to(device)\n",
        "\n",
        "# Define a linear regression model\n",
        "class LinearRegressionModel(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(input_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "# Create the model\n",
        "input_size = 1  # 10 input features\n",
        "output_size = 1  # 1 output (predicted value)\n",
        "model = LinearRegressionModel(input_size, output_size)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.02)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 5000\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass\n",
        "    outputs = model(X_tensor)\n",
        "    loss = criterion(outputs, y_tensor)\n",
        "\n",
        "    # Backward pass and optimization\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # print loss every 500 steps\n",
        "    if (epoch + 1) % 500 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Get the final model parameters\n",
        "final_parameters = model.state_dict()\n",
        "print(\"Final model parameters:\")\n",
        "for param_name, param_value in final_parameters.items():\n",
        "  print(param_name, param_value)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NroPj9HVKHUa"
      },
      "source": [
        "We can run evaluation on a new data point"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "vSh6a7keKKt9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([5.1048])\n"
          ]
        }
      ],
      "source": [
        "X_test = torch.Tensor([1]).to(device)\n",
        "with torch.no_grad():\n",
        "  print(model(X_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iw5LWv1qKiez"
      },
      "source": [
        "## 3. A more complex model\n",
        "\n",
        "credit: MIT 6.830\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "2VGOGMG3LKEr"
      },
      "outputs": [],
      "source": [
        "# getting MNIST data\n",
        "import torchvision\n",
        "mnist_train = torchvision.datasets.MNIST(root='./data', download=True, train=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "P7glHo6eLV7o"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This is a digit 2:\n",
            "<class 'PIL.Image.Image'>\n"
          ]
        }
      ],
      "source": [
        "image, label = mnist_train[5]\n",
        "print('This is a digit {}:'.format(label))\n",
        "image\n",
        "\n",
        "print(type(image))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ueFQMx5DLlQC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training set size:\t60000\n",
            "validation set size:\t10000\n"
          ]
        }
      ],
      "source": [
        "# define data preprocessing\n",
        "transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize(mean=(0.5,), std=(0.5,)),  # [0, 1] range => [-1, 1] range\n",
        "])\n",
        "\n",
        "mnist_train = torchvision.datasets.MNIST(root='./data', download=True, train=True,\n",
        "                                         transform=transform)\n",
        "mnist_val = torchvision.datasets.MNIST(root='./data', download=True, train=False,\n",
        "                                         transform=transform)\n",
        "\n",
        "print('training set size:\\t{}'.format(len(mnist_train)))\n",
        "print('validation set size:\\t{}'.format(len(mnist_val)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "5UHDeXwtLvp6"
      },
      "outputs": [],
      "source": [
        "batch_size = 512\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(mnist_train,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True,                   # shuffle training set\n",
        "                                           num_workers=2,                  # turns on multi-processing loading so training is not blocked by data loading\n",
        "                                           pin_memory=True)                # pin_memory allows faster transfer from CPU to GPU\n",
        "val_loader = torch.utils.data.DataLoader(mnist_val,\n",
        "                                         batch_size=batch_size,\n",
        "                                         num_workers=2,\n",
        "                                         pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0L1sev6L07D"
      },
      "source": [
        "some testing..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "OEC6EW1xL0LM"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/wenqifan/Desktop/image processing/tutorial_2/.venv/lib/python3.14/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "batched image tensor shape: torch.Size([512, 1, 28, 28])\n",
            "batched label tensor shape: torch.Size([512])\n"
          ]
        }
      ],
      "source": [
        "# Each element yielded by `train_loader` (a Python iterable) is still a 2-tuple,\n",
        "# but now consisting of a batched image tensor, and a batched label tensor.\n",
        "\n",
        "images, labels = next(iter(train_loader))\n",
        "print('batched image tensor shape: {}'.format(images.shape))\n",
        "print('batched label tensor shape: {}'.format(labels.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "UVzfYhQwMEpa"
      },
      "outputs": [],
      "source": [
        "class MyNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(in_features=16 * 5 * 5, out_features=120)\n",
        "        self.fc2 = nn.Linear(in_features=120, out_features=84)\n",
        "        self.fc3 = nn.Linear(in_features=84, out_features=10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.conv1(x))\n",
        "        out = F.max_pool2d(out, 2)\n",
        "        out = F.relu(self.conv2(out))\n",
        "        out = F.max_pool2d(out, 2)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = F.relu(self.fc1(out))\n",
        "        out = F.relu(self.fc2(out))\n",
        "        out = self.fc3(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfMv6PGdL_X0"
      },
      "source": [
        "We will use a convolutional network for classification. The following architecture is adapted from the famous [LeNet-5](https://ieeexplore.ieee.org/document/726791) [1].\n",
        "\n",
        "[1] LeCun, Yann, et al. \"Gradient-based learning applied to document recognition.\" Proceedings of the IEEE 86.11 (1998): 2278-2324."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1aginqkMYkL"
      },
      "source": [
        "some testing..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "K_K8nXduMYEr"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([8, 10])\n"
          ]
        }
      ],
      "source": [
        "model = MyNet().to(device)\n",
        "random_input = torch.randn(8, 1, 28, 28, device=device)\n",
        "output = model(random_input)\n",
        "print(output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FobszALIMpW0"
      },
      "source": [
        "## In-class activity: finish training/validation loop\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Initialize model, loss function, and optimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = MyNet().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Training parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_epochs = 10\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Training and validation loop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10]\n",
            "Train Loss: 0.7280, Train Acc: 81.63%\n",
            "Val Loss: 0.1950, Val Acc: 94.48%\n",
            "--------------------------------------------------\n",
            "Epoch [2/10]\n",
            "Train Loss: 0.1570, Train Acc: 95.28%\n",
            "Val Loss: 0.1207, Val Acc: 96.30%\n",
            "--------------------------------------------------\n",
            "Epoch [3/10]\n",
            "Train Loss: 0.1021, Train Acc: 96.91%\n",
            "Val Loss: 0.0896, Val Acc: 97.25%\n",
            "--------------------------------------------------\n",
            "Epoch [4/10]\n",
            "Train Loss: 0.0783, Train Acc: 97.56%\n",
            "Val Loss: 0.0668, Val Acc: 97.92%\n",
            "--------------------------------------------------\n",
            "Epoch [5/10]\n",
            "Train Loss: 0.0646, Train Acc: 98.00%\n",
            "Val Loss: 0.0537, Val Acc: 98.33%\n",
            "--------------------------------------------------\n",
            "Epoch [6/10]\n",
            "Train Loss: 0.0531, Train Acc: 98.33%\n",
            "Val Loss: 0.0474, Val Acc: 98.47%\n",
            "--------------------------------------------------\n",
            "Epoch [7/10]\n",
            "Train Loss: 0.0478, Train Acc: 98.54%\n",
            "Val Loss: 0.0420, Val Acc: 98.72%\n",
            "--------------------------------------------------\n",
            "Epoch [8/10]\n",
            "Train Loss: 0.0419, Train Acc: 98.64%\n",
            "Val Loss: 0.0445, Val Acc: 98.62%\n",
            "--------------------------------------------------\n",
            "Epoch [9/10]\n",
            "Train Loss: 0.0376, Train Acc: 98.83%\n",
            "Val Loss: 0.0394, Val Acc: 98.81%\n",
            "--------------------------------------------------\n",
            "Epoch [10/10]\n",
            "Train Loss: 0.0340, Train Acc: 98.95%\n",
            "Val Loss: 0.0361, Val Acc: 98.83%\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(num_epochs):\n",
        "    # Training phase\n",
        "    model.train()  # Set model to training mode\n",
        "    train_loss = 0.0\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "    \n",
        "    for images, labels in train_loader:\n",
        "        # Move data to device\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Calculate accuracy\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        train_total += labels.size(0)\n",
        "        train_correct += (predicted == labels).sum().item()\n",
        "        train_loss += loss.item()\n",
        "    \n",
        "    # Validation phase\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    val_loss = 0.0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    \n",
        "    with torch.no_grad():  # Disable gradient computation for validation\n",
        "        for images, labels in val_loader:\n",
        "            # Move data to device\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            \n",
        "            # Forward pass\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            \n",
        "            # Calculate accuracy\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            val_total += labels.size(0)\n",
        "            val_correct += (predicted == labels).sum().item()\n",
        "            val_loss += loss.item()\n",
        "    \n",
        "    # Print statistics\n",
        "    train_loss /= len(train_loader)\n",
        "    train_acc = 100 * train_correct / train_total\n",
        "    val_loss /= len(val_loader)\n",
        "    val_acc = 100 * val_correct / val_total\n",
        "    \n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}]')\n",
        "    print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
        "    print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
        "    print('-' * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to mnist_model.pth\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model_path = 'mnist_model.pth'\n",
        "torch.save(model.state_dict(), model_path)\n",
        "print(f'Model saved to {model_path}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded successfully!\n",
            "Model is on device: cpu\n",
            "\n",
            "Test prediction:\n",
            "  True label: 7\n",
            "  Predicted: 7\n",
            "  Correct: True\n"
          ]
        }
      ],
      "source": [
        "\n",
        "loaded_model = MyNet().to(device)\n",
        "\n",
        "# Load the state_dict\n",
        "loaded_model.load_state_dict(torch.load(model_path))\n",
        "loaded_model.eval()  # Set to evaluation mode\n",
        "\n",
        "print('Model loaded successfully!')\n",
        "print(f'Model is on device: {next(loaded_model.parameters()).device}')\n",
        "\n",
        "# Verify the model works by testing on a sample\n",
        "with torch.no_grad():\n",
        "    sample_image, sample_label = next(iter(val_loader))\n",
        "    sample_image = sample_image[0:1].to(device)  # Take first image\n",
        "    sample_label = sample_label[0:1].to(device)\n",
        "    \n",
        "    output = loaded_model(sample_image)\n",
        "    _, predicted = torch.max(output, 1)\n",
        "    \n",
        "    print(f'\\nTest prediction:')\n",
        "    print(f'  True label: {sample_label.item()}')\n",
        "    print(f'  Predicted: {predicted.item()}')\n",
        "    print(f'  Correct: {predicted.item() == sample_label.item()}')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
